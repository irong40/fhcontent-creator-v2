---
phase: 02-error-infrastructure
plan: "02-03"
type: execute
wave: 2
depends_on:
  - "02-01"
files_modified:
  - D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-heartbeat.json
autonomous: false
requirements:
  - MON-01

must_haves:
  truths:
    - "canary-heartbeat workflow fires every 1 minute via Schedule Trigger"
    - "Each fire inserts a row into pipeline_runs with status = 'heartbeat'"
    - "workflow_name column value is exactly 'canary-heartbeat'"
    - "pipeline_runs rows are queryable by external monitoring (Supabase REST API)"
    - "Freshness check: MAX(started_at) WHERE workflow_name='canary-heartbeat' is never older than 2 minutes"
    - "canary-heartbeat.json exported to n8n-workflows/"
  artifacts:
    - path: "D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-heartbeat.json"
      provides: "Exportable n8n workflow JSON for canary heartbeat"
      contains: "canary-heartbeat"
  key_links:
    - from: "Schedule Trigger (1 min)"
      to: "pipeline_runs table"
      via: "Supabase node INSERT with status=heartbeat"
      pattern: "pipeline_runs"
    - from: "External monitoring query"
      to: "pipeline_runs.started_at"
      via: "Supabase REST API GET /rest/v1/pipeline_runs?workflow_name=eq.canary-heartbeat"
      pattern: "canary-heartbeat"
---

<objective>
Upgrade the existing canary-timezone-test workflow into a production-grade canary heartbeat.
The upgraded workflow fires every 1 minute and writes a heartbeat row to pipeline_runs, making
the n8n instance's liveness externally verifiable via the Supabase REST API. This is the
simplest possible uptime signal: if MAX(started_at) WHERE workflow_name='canary-heartbeat'
is older than 2 minutes, the n8n instance is down or stalled.
</objective>

<context>
@D:/Projects/fhcontent-creator-v2/.planning/ROADMAP.md
@D:/Projects/fhcontent-creator-v2/.planning/STATE.md
</context>

<tasks>
<task type="auto">
  <name>Task 1: Inspect existing canary-timezone-test workflow</name>
  <files>n8n UI, D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-timezone-test.json</files>
  <action>
  Open http://localhost:5678. Find the workflow named "canary-timezone-test" (created in Phase 1).

  Read its existing node structure. It likely has:
  - Schedule Trigger (some interval)
  - Possibly a Set or Code node

  Decisions based on what you find:
  - If the workflow has no other purpose beyond testing, RENAME it to "canary-heartbeat"
    (click the workflow name at the top to rename in-place)
  - If it has useful timezone test logic you want to preserve, create a NEW workflow named
    "canary-heartbeat" and leave canary-timezone-test as-is

  Either way, the result is a workflow named exactly "canary-heartbeat" that is the subject
  of the remaining tasks in this plan.
  </action>
  <verify>
  A workflow named "canary-heartbeat" exists in the n8n workflow list (or will after Task 2).
  </verify>
  <done>Decided on rename vs new workflow. "canary-heartbeat" name is reserved.</done>
</task>

<task type="auto">
  <name>Task 2: Configure Schedule Trigger for 1-minute interval</name>
  <files>n8n UI</files>
  <action>
  In the canary-heartbeat workflow, configure the Schedule Trigger node:

  - Trigger Interval: Every 1 Minute
    OR in cron expression mode: * * * * * (every minute)
  - Timezone: America/New_York (must match GENERIC_TIMEZONE set in Phase 1)

  In n8n 2.9.0, the Schedule node UI:
  - Click the Schedule Trigger node
  - Set "Trigger Interval" = "Minutes"
  - Set "Minutes Between Triggers" = 1
  - OR switch to cron mode and enter: * * * * *

  NOTE: 1-minute Schedule Trigger is the minimum interval in n8n. Do not use 0 or sub-minute.
  </action>
  <verify>
  Schedule Trigger node shows "Every Minute" or cron "* * * * *" in the node configuration panel.
  </verify>
  <done>Schedule Trigger fires every 60 seconds.</done>
</task>

<task type="auto">
  <name>Task 3: Add Supabase insert node for heartbeat rows</name>
  <files>n8n UI</files>
  <action>
  In the canary-heartbeat workflow, add (or replace the existing output node with) a Supabase node:

  ADD/CONFIGURE Supabase node (named "Write Heartbeat"):
  - Type: Supabase node (n8n-nodes-base.supabase)
  - Credential: "Supabase Service Role"
  - Operation: Create
  - Table Name: pipeline_runs
  - Fields to Send:
    - workflow_name  →  canary-heartbeat  (static string, not expression)
    - status         →  heartbeat          (static string)
    - started_at     →  {{ $now.toISO() }}  (expression — current timestamp)

  Leave execution_id and correlation_id as null (not set). These are optional columns.

  Set "Continue on Error" = true on this node. A Supabase outage must not cascade to alarm.

  Connect Schedule Trigger → Write Heartbeat.

  Remove any intermediate nodes that were part of the old canary-timezone-test logic
  unless they are still useful (e.g., a Set node extracting timezone info is fine to keep
  between the Schedule Trigger and the Supabase insert for debugging purposes).

  Save the workflow with Ctrl+S.
  </action>
  <verify>
  Node list in canary-heartbeat shows: Schedule Trigger → (optional Set) → Write Heartbeat (Supabase).
  The Supabase node is configured for pipeline_runs with workflow_name = 'canary-heartbeat'.
  </verify>
  <done>Supabase insert node is connected and configured correctly.</done>
</task>

<task type="auto">
  <name>Task 4: Activate and verify live heartbeat rows</name>
  <files>n8n UI, Supabase SQL editor</files>
  <action>
  Activate the canary-heartbeat workflow (toggle Active = ON in top-right of workflow editor,
  or from the workflow list page).

  Wait 2–3 minutes for the schedule to fire at least twice.

  In Supabase SQL editor, run:
  ```sql
  SELECT id, workflow_name, status, started_at
  FROM pipeline_runs
  WHERE workflow_name = 'canary-heartbeat'
  ORDER BY started_at DESC
  LIMIT 10;
  ```

  Expected: rows appearing approximately 1 minute apart, all with status = 'heartbeat'.

  Then verify freshness check (this is the external monitoring query):
  ```sql
  SELECT
      workflow_name,
      MAX(started_at) AS last_heartbeat,
      NOW() - MAX(started_at) AS age,
      CASE
          WHEN NOW() - MAX(started_at) < INTERVAL '2 minutes' THEN 'HEALTHY'
          ELSE 'STALE'
      END AS health_status
  FROM pipeline_runs
  WHERE workflow_name = 'canary-heartbeat'
  GROUP BY workflow_name;
  ```

  health_status must show 'HEALTHY'.

  Also verify via n8n execution log:
  - In n8n, open Executions (left sidebar)
  - Filter by workflow: canary-heartbeat
  - At least 2 successful executions should appear
  </action>
  <verify>
  pipeline_runs has multiple rows with workflow_name='canary-heartbeat' and status='heartbeat'.
  Freshness query shows health_status = 'HEALTHY'.
  n8n executions log shows green (success) executions for canary-heartbeat.
  </verify>
  <done>Live heartbeat confirmed. Rows accumulating in pipeline_runs at 1-minute intervals.</done>
</task>

<task type="auto">
  <name>Task 5: Export updated workflow JSON</name>
  <files>D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-heartbeat.json</files>
  <action>
  Export the canary-heartbeat workflow from n8n:

  Method A (UI): Open canary-heartbeat → three-dot menu → Download
  Save to: D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-heartbeat.json

  Method B (API):
  ```bash
  curl -s http://localhost:5678/api/v1/workflows \
    -H "X-N8N-API-KEY: $(grep N8N_API_KEY D:/n8n/.env | cut -d= -f2)" \
    | python3 -c "
  import json, sys
  workflows = json.load(sys.stdin)
  for wf in workflows.get('data', []):
      if wf['name'] == 'canary-heartbeat':
          print(json.dumps(wf, indent=2))
          break
  " > "D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-heartbeat.json"
  ```

  The old canary-timezone-test.json in n8n-workflows/ may now be outdated. Either:
  - Delete it if the workflow was renamed (not duplicated)
  - Leave it if the original canary-timezone-test workflow still exists separately

  Validate JSON:
  ```bash
  python3 -c "import json; d=json.load(open('D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-heartbeat.json')); print('Name:', d.get('name')); print('Valid JSON')"
  ```
  </action>
  <verify>
  File D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-heartbeat.json exists.
  Python JSON parse succeeds. Name field = 'canary-heartbeat'.
  </verify>
  <done>canary-heartbeat.json saved to n8n-workflows/ directory.</done>
</task>
</tasks>

<verification>
Final verification checklist:

1. Workflow active in n8n:
   - canary-heartbeat workflow shows Active (green) in workflow list

2. Database rows accumulating:
   SELECT COUNT(*), MAX(started_at) FROM pipeline_runs WHERE workflow_name='canary-heartbeat';
   -- COUNT > 0, MAX within last 2 minutes

3. Freshness check passes:
   SELECT CASE WHEN NOW()-MAX(started_at) < INTERVAL '2 minutes' THEN 'OK' ELSE 'FAIL' END
   FROM pipeline_runs WHERE workflow_name='canary-heartbeat';
   -- Returns 'OK'

4. JSON file exported:
   ls -la "D:/Projects/fhcontent-creator-v2/n8n-workflows/canary-heartbeat.json"
   -- File exists and is > 200 bytes

5. External REST API accessibility (optional smoke test):
   curl "https://qjpujskwqaehxnqypxzu.supabase.co/rest/v1/pipeline_runs?workflow_name=eq.canary-heartbeat&select=started_at&order=started_at.desc&limit=1" \
     -H "apikey: <SUPABASE_SERVICE_ROLE_KEY>" \
     -H "Authorization: Bearer <SUPABASE_SERVICE_ROLE_KEY>"
   -- Returns a JSON array with one object containing started_at
</verification>

<success_criteria>
- canary-heartbeat workflow is active in n8n
- Schedule Trigger configured for 1-minute interval in America/New_York timezone
- Each trigger inserts a row into pipeline_runs with workflow_name='canary-heartbeat' and status='heartbeat'
- Rows are accumulating (verified by COUNT > 0 and recency)
- Freshness query shows HEALTHY (last heartbeat within 2 minutes)
- canary-heartbeat.json exported to n8n-workflows/
- Supabase insert node has Continue on Error = true
</success_criteria>

<output>
After completion, create summary file:
D:/Projects/fhcontent-creator-v2/.planning/phases/02-error-infrastructure/02-03-SUMMARY.md

Include:
- n8n workflow ID for canary-heartbeat
- Whether this was a rename of canary-timezone-test or a new workflow
- Row count in pipeline_runs for workflow_name='canary-heartbeat' at time of verification
- Most recent started_at value
- Confirmation that canary-heartbeat.json is valid JSON
</output>
