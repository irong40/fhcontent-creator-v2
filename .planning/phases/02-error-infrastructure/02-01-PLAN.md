---
phase: 02-error-infrastructure
plan: "02-01"
type: execute
wave: 2
depends_on:
  - "01-04"
files_modified:
  - D:/Projects/fhcontent-creator-v2/supabase/migrations/20260226000000_pipeline_tables.sql
autonomous: true
requirements:
  - ERR-03
  - MON-02
  - ERR-05

must_haves:
  truths:
    - "Migration file 20260226000000_pipeline_tables.sql exists and is valid SQL"
    - "pipeline_errors table exists in Supabase with all required columns"
    - "pipeline_runs table exists in Supabase with all required columns"
    - "pipeline_dlq table exists in Supabase with all required columns"
    - "RLS is enabled on all three tables"
    - "service_role can INSERT on all three tables"
    - "authenticated role can SELECT on all three tables"
    - "supabase db push completes without errors"
  artifacts:
    - path: "D:/Projects/fhcontent-creator-v2/supabase/migrations/20260226000000_pipeline_tables.sql"
      provides: "DDL for pipeline_errors, pipeline_runs, pipeline_dlq"
      contains: "CREATE TABLE pipeline_errors"
  key_links:
    - from: "n8n WF-Error workflow (02-02)"
      to: "pipeline_errors table"
      via: "Supabase REST API insert"
      pattern: "pipeline_errors"
    - from: "canary heartbeat workflow (02-03)"
      to: "pipeline_runs table"
      via: "Supabase REST API insert"
      pattern: "pipeline_runs"
    - from: "dead-letter queue logic (Phase 4+)"
      to: "pipeline_dlq table"
      via: "Supabase REST API insert"
      pattern: "pipeline_dlq"
---

<objective>
Create a single Supabase migration that provisions the three observability tables required for Phase 2:
pipeline_errors (structured error capture), pipeline_runs (execution audit trail), and pipeline_dlq
(dead-letter queue for unrecoverable failures). All tables get RLS policies scoped to service_role
inserts and authenticated reads. This is a pure SQL task — no n8n UI interaction needed.
</objective>

<context>
@D:/Projects/fhcontent-creator-v2/.planning/ROADMAP.md
@D:/Projects/fhcontent-creator-v2/.planning/STATE.md
</context>

<tasks>
<task type="auto">
  <name>Task 1: Create migration file with DDL for all three tables</name>
  <files>D:/Projects/fhcontent-creator-v2/supabase/migrations/20260226000000_pipeline_tables.sql</files>
  <action>
  Create the file at the exact path above with the following SQL content:

  ```sql
  -- Migration: 008_pipeline_tables
  -- Purpose: Observability tables for n8n workflow orchestration
  -- Phase: 02-error-infrastructure
  -- Tables: pipeline_errors, pipeline_runs, pipeline_dlq

  -- ============================================================
  -- pipeline_errors: Structured error capture from n8n workflows
  -- ============================================================
  CREATE TABLE IF NOT EXISTS pipeline_errors (
      id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      workflow_name   TEXT NOT NULL,
      node_name       TEXT,
      error_message   TEXT NOT NULL,
      execution_id    TEXT,
      correlation_id  TEXT,
      occurred_at     TIMESTAMPTZ NOT NULL DEFAULT NOW()
  );

  CREATE INDEX idx_pipeline_errors_workflow
      ON pipeline_errors (workflow_name, occurred_at DESC);
  CREATE INDEX idx_pipeline_errors_correlation
      ON pipeline_errors (correlation_id)
      WHERE correlation_id IS NOT NULL;
  CREATE INDEX idx_pipeline_errors_occurred
      ON pipeline_errors (occurred_at DESC);

  ALTER TABLE pipeline_errors ENABLE ROW LEVEL SECURITY;

  -- service_role can insert errors from n8n
  CREATE POLICY "service_role_insert_pipeline_errors"
      ON pipeline_errors FOR INSERT
      TO service_role
      WITH CHECK (true);

  -- authenticated users (admin dashboard) can read errors
  CREATE POLICY "authenticated_select_pipeline_errors"
      ON pipeline_errors FOR SELECT
      TO authenticated
      USING (true);

  -- ============================================================
  -- pipeline_runs: Execution audit trail for every workflow run
  -- ============================================================
  CREATE TABLE IF NOT EXISTS pipeline_runs (
      id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      execution_id    TEXT,
      workflow_name   TEXT NOT NULL,
      status          TEXT NOT NULL CHECK (status IN (
                          'started', 'completed', 'failed', 'heartbeat'
                      )),
      started_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
      completed_at    TIMESTAMPTZ,
      correlation_id  TEXT
  );

  CREATE INDEX idx_pipeline_runs_workflow
      ON pipeline_runs (workflow_name, started_at DESC);
  CREATE INDEX idx_pipeline_runs_status
      ON pipeline_runs (status, started_at DESC);
  CREATE INDEX idx_pipeline_runs_correlation
      ON pipeline_runs (correlation_id)
      WHERE correlation_id IS NOT NULL;
  -- Partial index for freshness check (heartbeat monitoring)
  CREATE INDEX idx_pipeline_runs_heartbeat
      ON pipeline_runs (workflow_name, started_at DESC)
      WHERE status = 'heartbeat';

  ALTER TABLE pipeline_runs ENABLE ROW LEVEL SECURITY;

  CREATE POLICY "service_role_insert_pipeline_runs"
      ON pipeline_runs FOR INSERT
      TO service_role
      WITH CHECK (true);

  CREATE POLICY "service_role_update_pipeline_runs"
      ON pipeline_runs FOR UPDATE
      TO service_role
      USING (true)
      WITH CHECK (true);

  CREATE POLICY "authenticated_select_pipeline_runs"
      ON pipeline_runs FOR SELECT
      TO authenticated
      USING (true);

  -- ============================================================
  -- pipeline_dlq: Dead-letter queue for unrecoverable failures
  -- ============================================================
  CREATE TABLE IF NOT EXISTS pipeline_dlq (
      id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      workflow_name   TEXT NOT NULL,
      correlation_id  TEXT,
      payload         JSONB NOT NULL DEFAULT '{}',
      error           TEXT NOT NULL,
      failed_at       TIMESTAMPTZ NOT NULL DEFAULT NOW(),
      retry_count     INTEGER NOT NULL DEFAULT 0
  );

  CREATE INDEX idx_pipeline_dlq_workflow
      ON pipeline_dlq (workflow_name, failed_at DESC);
  CREATE INDEX idx_pipeline_dlq_correlation
      ON pipeline_dlq (correlation_id)
      WHERE correlation_id IS NOT NULL;
  CREATE INDEX idx_pipeline_dlq_retry
      ON pipeline_dlq (retry_count, failed_at DESC);
  -- GIN index for payload querying (find by topic_id, etc.)
  CREATE INDEX idx_pipeline_dlq_payload
      ON pipeline_dlq USING GIN (payload);

  ALTER TABLE pipeline_dlq ENABLE ROW LEVEL SECURITY;

  CREATE POLICY "service_role_insert_pipeline_dlq"
      ON pipeline_dlq FOR INSERT
      TO service_role
      WITH CHECK (true);

  CREATE POLICY "service_role_update_pipeline_dlq"
      ON pipeline_dlq FOR UPDATE
      TO service_role
      USING (true)
      WITH CHECK (true);

  CREATE POLICY "authenticated_select_pipeline_dlq"
      ON pipeline_dlq FOR SELECT
      TO authenticated
      USING (true);

  -- ============================================================
  -- Helper view: recent errors in the last 24 hours
  -- ============================================================
  CREATE OR REPLACE VIEW v_recent_pipeline_errors AS
  SELECT
      workflow_name,
      node_name,
      error_message,
      correlation_id,
      occurred_at
  FROM pipeline_errors
  WHERE occurred_at > NOW() - INTERVAL '24 hours'
  ORDER BY occurred_at DESC;

  -- Helper view: workflow health (last run per workflow)
  CREATE OR REPLACE VIEW v_workflow_health AS
  SELECT DISTINCT ON (workflow_name)
      workflow_name,
      status,
      started_at AS last_run_at,
      completed_at,
      correlation_id
  FROM pipeline_runs
  ORDER BY workflow_name, started_at DESC;
  ```

  Save this file. Do NOT edit any previously applied migration (001–007).
  </action>
  <verify>
  Run:
    ls -la "D:/Projects/fhcontent-creator-v2/supabase/migrations/20260226000000_pipeline_tables.sql"
  File must exist and be non-empty.
  </verify>
  <done>Migration file exists with all three CREATE TABLE statements and RLS policies.</done>
</task>

<task type="auto">
  <name>Task 2: Push migration to Supabase</name>
  <files>supabase CLI</files>
  <action>
  From the project root D:/Projects/fhcontent-creator-v2, run:

  ```bash
  cd D:/Projects/fhcontent-creator-v2
  npx supabase migration list
  ```

  Verify the new migration 20260226000000 appears in the list as NOT yet applied.
  Then push:

  ```bash
  npx supabase db push
  ```

  If the supabase CLI is not installed globally, use:
  ```bash
  npx supabase@latest db push
  ```

  Expected output: "Applying migration 20260226000000_pipeline_tables.sql" followed by success.

  If you get a timestamp conflict (another migration was applied with same timestamp), rename the
  file to 20260226000001_pipeline_tables.sql and retry.
  </action>
  <verify>
  Run the following SQL in the Supabase dashboard SQL editor (project qjpujskwqaehxnqypxzu):

  ```sql
  SELECT table_name, row_security
  FROM information_schema.tables
  WHERE table_name IN ('pipeline_errors', 'pipeline_runs', 'pipeline_dlq')
    AND table_schema = 'public';
  ```

  All 3 rows must appear. Then verify policies:

  ```sql
  SELECT tablename, policyname, roles, cmd
  FROM pg_policies
  WHERE tablename IN ('pipeline_errors', 'pipeline_runs', 'pipeline_dlq')
  ORDER BY tablename, cmd;
  ```

  Expect 2 policies per table (INSERT for service_role, SELECT for authenticated),
  plus UPDATE policies on pipeline_runs and pipeline_dlq.
  </verify>
  <done>Migration applied. All 3 tables and 7 policies exist in production Supabase.</done>
</task>

<task type="auto">
  <name>Task 3: Smoke-test insert via service role</name>
  <files>Supabase SQL editor</files>
  <action>
  In the Supabase dashboard SQL editor, run as service_role (switch to service_role context or use
  the SQL editor which runs as postgres/service_role by default):

  ```sql
  -- Test insert into pipeline_errors
  INSERT INTO pipeline_errors (workflow_name, node_name, error_message, execution_id, correlation_id)
  VALUES ('test-workflow', 'test-node', 'smoke test error', 'exec-smoke-001', 'corr-smoke-001')
  RETURNING id, occurred_at;

  -- Test insert into pipeline_runs
  INSERT INTO pipeline_runs (workflow_name, status, correlation_id)
  VALUES ('test-workflow', 'completed', 'corr-smoke-001')
  RETURNING id, started_at;

  -- Test insert into pipeline_dlq
  INSERT INTO pipeline_dlq (workflow_name, correlation_id, payload, error, retry_count)
  VALUES ('test-workflow', 'corr-smoke-001', '{"topic_id": "test-123"}', 'smoke test', 0)
  RETURNING id, failed_at;

  -- Clean up smoke test rows
  DELETE FROM pipeline_errors WHERE execution_id = 'exec-smoke-001';
  DELETE FROM pipeline_runs WHERE correlation_id = 'corr-smoke-001';
  DELETE FROM pipeline_dlq WHERE correlation_id = 'corr-smoke-001';
  ```

  All four INSERT statements must return rows. DELETE must succeed.
  </action>
  <verify>
  Each INSERT RETURNING must show a valid UUID and timestamp. No errors.
  </verify>
  <done>All three tables accept inserts and deletes via SQL editor (service_role context).</done>
</task>
</tasks>

<verification>
Final verification checklist:

1. File check:
   ls "D:/Projects/fhcontent-creator-v2/supabase/migrations/20260226000000_pipeline_tables.sql"

2. Table check in Supabase SQL editor:
   SELECT COUNT(*) FROM information_schema.tables
   WHERE table_name IN ('pipeline_errors','pipeline_runs','pipeline_dlq')
   AND table_schema = 'public';
   -- Must return 3

3. RLS check:
   SELECT tablename FROM pg_tables
   WHERE tablename IN ('pipeline_errors','pipeline_runs','pipeline_dlq')
   AND rowsecurity = true;
   -- Must return 3 rows

4. Policy check:
   SELECT COUNT(*) FROM pg_policies
   WHERE tablename IN ('pipeline_errors','pipeline_runs','pipeline_dlq');
   -- Must return 7 (2+3+2)

5. View check:
   SELECT viewname FROM pg_views
   WHERE viewname IN ('v_recent_pipeline_errors','v_workflow_health');
   -- Must return 2 rows
</verification>

<success_criteria>
- Migration file 20260226000000_pipeline_tables.sql committed to the migrations directory
- All three tables exist in the public schema of Supabase project qjpujskwqaehxnqypxzu
- RLS enabled on pipeline_errors, pipeline_runs, pipeline_dlq
- service_role INSERT policy on all three tables
- authenticated SELECT policy on all three tables
- service_role UPDATE policy on pipeline_runs and pipeline_dlq
- v_recent_pipeline_errors and v_workflow_health views exist
- Smoke test inserts succeed and clean up without errors
- No previously applied migrations were modified
</success_criteria>

<output>
After completion, create summary file:
D:/Projects/fhcontent-creator-v2/.planning/phases/02-error-infrastructure/02-01-SUMMARY.md

Include:
- Migration filename applied
- Names of all 3 tables created
- Names of views created
- Policy count per table
- Any timestamp conflict encountered and resolution
</output>
